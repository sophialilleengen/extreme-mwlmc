#!/bin/bash
#SBATCH --job-name=MW00 	                   # set job name
#SBATCH --mail-user=michael.petersen@roe.ac.uk # set your mail address
#SBATCH -p gpu                             # set partition (queue)
#SBATCH --qos=standard
#SBATCH --nodes=1                          # set node number
#SBATCH --gres=gpu:4                       # set GPU number
#SBATCH --ntasks-per-gpu=1                         # set task number
#SBATCH --cpus-per-task=8
#SBATCH --mem=128G                          # set memory request sbatch: fatal: --mem, --mem-per-cpu, and --mem-per-gpu are mutually exclusive.
#SBATCH --time=47:00:00                        # set max wallclock time
#SBATCH --output=job-%N-%j.out                 # set output log name
#SBATCH --error=job-%N-%j.error                # set error log name %N=first node, %j=job number
#SBATCH --mail-type=ALL                        # set mail alerts

# set up multithreading
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

# load modules
module use /home/y07/shared/tursa-modules
module load cmake
module load gcc/9.3.0 cuda/11.4.1  openmpi/4.1.1-cuda11.4.1

# append a new set of libraries to point at EXP executable:
export LD_LIBRARY_PATH=/home/dp309/dp309/dc-pete4/lib:$LD_LIBRARY_PATH

# change directory to proper location
cd /home/dp309/dp309/shared/extreme-mwlmc/models/tursa/MW/

# stamp output with details
pwd; hostname; date

# print the current path to libraries:
echo $LD_LIBRARY_PATH

# set the execution command
export COMMAND="mpirun -v /home/dp309/dp309/dc-pete4/bin/exp run_mw_model_gpu00.yml"

# stamp output with execution command
echo $COMMAND

# run execution command
$COMMAND

# stamp output with end time
date
